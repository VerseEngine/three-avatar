<!-- Do not edit this file. It is automatically generated by API Documenter. -->

[Home](./index.md) &gt; [three-avatar](./three-avatar.md) &gt; [Avatar](./three-avatar.avatar.md) &gt; [lipSync](./three-avatar.avatar.lipsync.md)

## Avatar.lipSync() method

Synchronize lip movements with the voice.

**Signature:**

```typescript
lipSync(kiss: number, lipsClosed: number, jaw: number): void;
```

## Parameters

|  Parameter | Type | Description |
|  --- | --- | --- |
|  kiss | number |  |
|  lipsClosed | number |  |
|  jaw | number |  |

**Returns:**

void

## Remarks

see [Web-based live speech-driven lip-sync](https://repositori.upf.edu/bitstream/handle/10230/28139/llorach_VSG16_web.pdf)

summary

```
  Our method generates
  reliable speech animation based on live speech using three blend
  shapes and no training, and it only needs manual adjustment of
  three parameters for each speaker (sensitivity, smoothness and
  vocal tract length).
```

## Example


```ts
  import {
    createAvatar,
    addMirrorHUD,
    ...
    Lipsync,
  } from "three-avatar";

  ...

  const ms = await navigator.mediaDevices.getUserMedia({
    audio: true,
  });
  const lipSync = new Lipsync(THREE.AudioContext.getContext(), ms);

  ...

  renderer.setAnimationLoop(() => {
    ...
    avatar.lipSync(...lipSync.update());
  });
```

