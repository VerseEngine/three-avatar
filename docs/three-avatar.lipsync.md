<!-- Do not edit this file. It is automatically generated by API Documenter. -->

[Home](./index.md) &gt; [@verseengine/three-avatar](./three-avatar.md) &gt; [Lipsync](./three-avatar.lipsync.md)

## Lipsync() function

Slightly customized [threelipsync module](https://github.com/gerardllorach/threelipsync)<!-- -->.

**Signature:**

```typescript
export declare function Lipsync(context: AudioContext, ms: MediaStream, threshold?: number, smoothness?: number, pitch?: number): void;
```

## Parameters

|  Parameter | Type | Description |
|  --- | --- | --- |
|  context | AudioContext |  |
|  ms | MediaStream |  |
|  threshold | number | _(Optional)_ |
|  smoothness | number | _(Optional)_ |
|  pitch | number | _(Optional)_ |

**Returns:**

void

## Remarks


```
--------------------- THREELIPSYNC MODULE --------------------
Computes the values of THREE blend shapes (kiss, lips closed and mouth open/jaw)
To do so, it computes the energy of THREE frequency bands in real time.
he webpage needs to be https in order to get the microphone. If using external
audio files from URL, they need to be from a https origin.

Author: Gerard Llorach
Paper: G. Llorach, A. Evans, J. Blat, G. Grimm, V. Hohmann. Web-based live speech-driven
lip-sync, Proceedings of VS-Games 2016, September, Barcelona
Date: Nov 2016
https://repositori.upf.edu/bitstream/handle/10230/28139/llorach_VSG16_web.pdf
License: MIT
```

